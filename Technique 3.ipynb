{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "path='H:/Thesis/[4-2]/Dataset/train/WorkingDataset/4-PDR/3993_right.jpeg'\n",
    "image = cv2.imread(path)\n",
    "\n",
    "'''Convert in gray'''\n",
    "gray_image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "''' Cropping'''\n",
    "h,w=gray_image.shape[:2]\n",
    "x1,y1=int(h*.05),int(w*.15)\n",
    "x2,y2=int(h*.95),int(w*.85)\n",
    "croped_image=gray_image[x1:x2,y1:y2]\n",
    "cv2.imshow('After cropping ',croped_image)\n",
    "\n",
    "'''Resizing'''\n",
    "i_s3=cv2.resize(croped_image,(612,512),interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('3.Scaling- Skewed Interpolation',i_s3)\n",
    "\n",
    "'''cv2.imshow('Original',image)\n",
    "cv2.imshow('Gray Scale',gray_image)'''\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "rgb_image = cv2.imread('eye.jpg')\n",
    "gray_image=cv2.cvtColor(rgb_image, cv2.COLOR_BGR2GRAY)\n",
    "hsv=cv2.cvtColor(rgb_image, cv2.COLOR_BGR2HSV)\n",
    "green_image = rgb_image.copy()\n",
    "green_image[:,:,0] = 0\n",
    "green_image[:,:,2] = 0\n",
    "cv2.imshow('G-RGB', green_image)\n",
    "imagem = cv2.bitwise_not(green_image)\n",
    "blur = cv2.medianBlur(green_image,5)\n",
    "cv2.imshow('HSV',hsv)\n",
    "cv2.imshow('G-complement', imagem)\n",
    "cv2.imshow('Median filter', blur)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-efbd1d8b26ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrgb_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eye.jpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# create a CLAHE object (Arguments are optional).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclahe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateCLAHE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclipLimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtileGridSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclahe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "rgb_image = cv2.imread('eye.jpg',0)\n",
    "# create a CLAHE object (Arguments are optional).\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "cl1 = clahe.apply(rgb_image)\n",
    "cv2.imshow('clahe_2.jpg',cl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img = cv2.imread('eye.jpg',0)\n",
    "# create a CLAHE object (Arguments are optional).\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "cl1 = clahe.apply(img) \n",
    "cv2.imshow('eye.jpg',cl1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "path='H:/Thesis/[4-2]/Dataset/train/WorkingDataset/4-PDR/3993_right.jpeg'\n",
    "\n",
    "#-----Reading the image-----------------------------------------------------\n",
    "#img = cv2.imread('eye.jpg', 1)\n",
    "img = cv2.imread('eye.jpg', 1)\n",
    "\n",
    "h,w=img.shape[:2]\n",
    "x1,y1=int(h*.05),int(w*.15)\n",
    "x2,y2=int(h*.95),int(w*.85)\n",
    "img=img[x1:x2,y1:y2]\n",
    "img=cv2.resize(img,(512,412),interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow(\"img\",img) \n",
    "\n",
    "gray_image=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Gray', gray_image)\n",
    "#-----Converting image to LAB Color model----------------------------------- \n",
    "lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "cv2.imshow(\"lab\",lab)\n",
    "\n",
    "#-----Splitting the LAB image to different channels-------------------------\n",
    "l, a, b = cv2.split(lab)\n",
    "cv2.imshow('l_channel', l)\n",
    "cv2.imshow('a_channel', a)\n",
    "cv2.imshow('b_channel', b)\n",
    "\n",
    "#-----Applying CLAHE to L-channel-------------------------------------------\n",
    "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "cl = clahe.apply(l)\n",
    "cv2.imshow('CLAHE output', cl)\n",
    "\n",
    "#-----Merge the CLAHE enhanced L-channel with the a and b channel-----------\n",
    "limg = cv2.merge((cl,a,b))\n",
    "cv2.imshow('limg', limg)\n",
    "\n",
    "#-----Converting image from LAB Color model to RGB model--------------------\n",
    "final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "cv2.imshow('final', final)\n",
    "\n",
    "gray_image=cv2.cvtColor(final, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('final Gray', gray_image)\n",
    "\n",
    "#_____END_____#\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image_path='H:/Thesis/[4-2]/Dataset/train/WorkingDataset/4-PDR/3993_right.jpeg'\n",
    "bgr = cv2.imread('eye.jpg')\n",
    "gridsize=8\n",
    "lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "lab_planes = cv2.split(lab)\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=4.0,tileGridSize=(gridsize,gridsize))\n",
    "\n",
    "lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "\n",
    "lab = cv2.merge(lab_planes)\n",
    "\n",
    "bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "cv2.imshow('CLAHE', bgr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contrast limited adaptive histogram equalization\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "# from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "def contrast_limited_adaptive_histogram_equalization(path, new_path):\n",
    "    create_directory(new_path)\n",
    "    create_directory(path)\n",
    "    dirs = [l for l in os.listdir(path) if l != '.DS_Store']\n",
    "    total = 0\n",
    "    #Amount of cropping\n",
    "    cropx= 1800\n",
    "    cropy= 1800\n",
    "    \n",
    "    for item in dirs:\n",
    "        img = io.imread(path+item)\n",
    "        y,x,channel = img.shape\n",
    "        startx = x//2-(cropx//2)\n",
    "        starty = y//2-(cropy//2)\n",
    "        img = img[starty:starty+cropy,startx:startx+cropx]#cropping\n",
    "        img = resize(img, (512,512))#resizing\n",
    "        \n",
    "        #Technique 3: Contrast limited adaptive histogram equalization\n",
    "        \n",
    "        #code start\n",
    "        gray_image=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #-----Converting image to LAB Color model----------------------------------- \n",
    "        lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        \n",
    "        #-----Splitting the LAB image to different channels-------------------------\n",
    "        l, a, b = cv2.split(lab)\n",
    "        cv2.imshow('l_channel', l)\n",
    "        cv2.imshow('a_channel', a)\n",
    "        cv2.imshow('b_channel', b)\n",
    "        \n",
    "        #-----Applying CLAHE to L-channel-------------------------------------------\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "        cl = clahe.apply(l)\n",
    "        \n",
    "        #-----Merge the CLAHE enhanced L-channel with the a and b channel-----------\n",
    "        limg = cv2.merge((cl,a,b))\n",
    "        \n",
    "        #-----Converting image from LAB Color model to RGB model--------------------\n",
    "        final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "        gray_image=cv2.cvtColor(final, cv2.COLOR_BGR2GRAY)\n",
    "        #code end\n",
    "        \n",
    "        io.imsave(str(new_path + item), final)\n",
    "        total += 1\n",
    "        print(total, \"Saving: \", item)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    contrast_limited_adaptive_histogram_equalization(path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Final dataset/0-Normal/', new_path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 3/0-Normal/')\n",
    "    contrast_limited_adaptive_histogram_equalization(path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Final dataset/1-Mild/', new_path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 3/1-Mild/')\n",
    "    contrast_limited_adaptive_histogram_equalization(path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Final dataset/2-Moderate/', new_path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 3/2-Moderate/')\n",
    "    contrast_limited_adaptive_histogram_equalization(path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Final dataset/3-Severe/', new_path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 3/3-Severe/')\n",
    "    contrast_limited_adaptive_histogram_equalization(path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Final dataset/4-PDR/', new_path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 3/4-PDR/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
