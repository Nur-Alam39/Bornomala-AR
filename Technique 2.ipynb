{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaptive median filter\n",
    "import os\n",
    "import sys\n",
    "# from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "def adaptive_median_filter(path, new_path):\n",
    "    create_directory(new_path)\n",
    "    dirs = [l for l in os.listdir(path) if l != '.DS_Store']\n",
    "    total = 0\n",
    "    #Amount of cropping\n",
    "    cropx= 1800\n",
    "    cropy= 1800\n",
    "    \n",
    "    for item in dirs:\n",
    "        img = io.imread(path+item)\n",
    "        y,x,channel = img.shape\n",
    "        startx = x//2-(cropx//2)\n",
    "        starty = y//2-(cropy//2)\n",
    "        img = img[starty:starty+cropy,startx:startx+cropx]#cropping\n",
    "        img = resize(img, (512,512))#resizing\n",
    "        \n",
    "        #Technique 2: Adaptive median filter\n",
    "    \n",
    "        io.imsave(str(new_path + item), green_image)\n",
    "        total += 1\n",
    "        print(total, \"Saving: \", item)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    adaptive_median_filter(path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 2/T2_Original/0-Normal', new_path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 2/T2_Processed/0-Normal')\n",
    "    adaptive_median_filter(path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 2/T2_Original/1-Mild', new_path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 2/T2_Processed/1-Mild')\n",
    "    adaptive_median_filter(path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 2/T2_Original/2-Moderate', new_path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 2/T2_Processed/2-Moderate')\n",
    "    adaptive_median_filter(path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 2/T2_Original/3-Severe', new_path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 2/T2_Processed/3-Severe')\n",
    "    adaptive_median_filter(path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 2/T2_Original/4-PDR', new_path='D:/Nur Alam_4th Batch(Thesis)/Kaggle Dataset/Train/Technique 2/T2_Processed/4-PDR')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cropping and resizeing\n",
    "import cv2\n",
    "path='H:/Thesis/[4-2]/Dataset/train/WorkingDataset/4-PDR/3993_right.jpeg'\n",
    "image = cv2.imread(path)\n",
    "\n",
    "'''Convert in gray'''\n",
    "gray_image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "''' Cropping'''\n",
    "h,w=gray_image.shape[:2]\n",
    "x1,y1=int(h*.05),int(w*.15)\n",
    "x2,y2=int(h*.95),int(w*.85)\n",
    "croped_image=gray_image[x1:x2,y1:y2]\n",
    "cv2.imshow('After cropping ',croped_image)\n",
    "\n",
    "'''Resizing'''\n",
    "i_s3=cv2.resize(croped_image,(612,512),interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('3.Scaling- Skewed Interpolation',i_s3)\n",
    "\n",
    "'''cv2.imshow('Original',image)\n",
    "cv2.imshow('Gray Scale',gray_image)'''\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
